# translator.py

import torch
from transformers import AutoModelForSeq2SeqLM, AutoTokenizer
from functools import lru_cache
from langdetect import detect

# Ğ˜ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞµĞ¼ Ğ´Ğ¸ÑÑ‚Ğ¸Ğ»Ğ»Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ½ÑƒÑ Ğ²ĞµÑ€ÑĞ¸Ñ Ğ´Ğ»Ñ ÑĞºĞ¾Ñ€Ğ¾ÑÑ‚Ğ¸ (Ğ¾ĞºĞ¾Ğ»Ğ¾ 2.4 Ğ“Ğ‘)
MODEL_NAME = "facebook/nllb-200-distilled-600M"

@lru_cache(maxsize=1)
def get_model():
    tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)
    model = AutoModelForSeq2SeqLM.from_pretrained(MODEL_NAME)
    model.eval()
    return tokenizer, model

# ĞšĞ°Ñ€Ñ‚Ğ° ÑĞ¾Ğ¾Ñ‚Ğ²ĞµÑ‚ÑÑ‚Ğ²Ğ¸Ñ ĞºĞ¾Ñ€Ğ¾Ñ‚ĞºĞ¸Ñ… ĞºĞ¾Ğ´Ğ¾Ğ² ĞºĞ¾Ğ´Ğ°Ğ¼ NLLB
NLLB_LANG_MAP = {
    "ru": "rus_Cyrl",
    "en": "eng_Latn",
    "th": "tha_Thai",
    "zh": "zho_Hans",
    "ja": "jpn_Jpan",
    "ko": "kor_Kore",
    "tr": "tur_Latn",
    "ar": "ary_Arab"
}

def translate_text(text: str, src_lang: str, tgt_lang: str) -> str:
    if not text or not text.strip():
        return ""

    tokenizer, model = get_model()
    
    # ĞŸĞ¾Ğ»ÑƒÑ‡Ğ°ĞµĞ¼ Ğ¿Ğ¾Ğ»Ğ½Ñ‹Ğµ ĞºĞ¾Ğ´Ñ‹ ÑĞ·Ñ‹ĞºĞ¾Ğ² Ğ´Ğ»Ñ NLLB
    src_code = NLLB_LANG_MAP.get(src_lang, "eng_Latn")
    tgt_code = NLLB_LANG_MAP.get(tgt_lang, "rus_Cyrl")

    inputs = tokenizer(text, return_tensors="pt")
    
    translated_tokens = model.generate(
        **inputs, 
        forced_bos_token_id=tokenizer.lang_code_to_id[tgt_code], 
        max_length=128
    )
    
    return tokenizer.batch_decode(translated_tokens, skip_special_tokens=True)[0]


# ------------------ LANGUAGE DETECTION ------------------

LANG_DISPLAY = {
    "ru": "ğŸ‡·ğŸ‡º Ğ ÑƒÑÑĞºĞ¸Ğ¹",
    "en": "ğŸ‡¬ğŸ‡§ English",
    "th": "ğŸ‡¹ğŸ‡­ à¹„à¸—à¸¢ (Thai)",
    "zh": "ğŸ‡¨ğŸ‡³ ä¸­æ–‡",
    "ja": "ğŸ‡¯ğŸ‡µ æ—¥æœ¬èª",
    "ko": "ğŸ‡°ğŸ‡· í•œêµ­ì–´",
    "vi": "ğŸ‡»ğŸ‡³ Tiáº¿ng Viá»‡t",
    "tr": "ğŸ‡¹ğŸ‡· TÃ¼rkÃ§e",
    "ar": "ğŸ‡¸ğŸ‡¦ Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©",
    "he": "ğŸ‡®ğŸ‡± ×¢×‘×¨×™×ª",
    "id": "ğŸ‡®ğŸ‡© Bahasa Indonesia",
    "ms": "ğŸ‡²ğŸ‡¾ Bahasa Melayu",
    "fa": "ğŸ‡®ğŸ‡· ÙØ§Ø±Ø³ÛŒ",
    "ka": "ğŸ‡¬ğŸ‡ª áƒ¥áƒáƒ áƒ—áƒ£áƒšáƒ˜",
    "hy": "ğŸ‡¦ğŸ‡² Õ€Õ¡ÕµÕ¥Ö€Õ¥Õ¶",
}


def detect_lang_code(text: str) -> str:
    try:
        return detect(text)
    except Exception:
        return "en"


def detect_lang_for_display(text: str) -> str:
    code = detect_lang_code(text)
    return LANG_DISPLAY.get(code, f"ğŸŒ {code}")
